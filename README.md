# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ1

### ‚Ññ1 - –í—ã–≤–æ–¥ –ø—Ä–≥—Ä–∞–º–º—ã: –∏–º—è –∏ –≤–æ–∑—Ä–∞—Å—Ç —á–µ—Ä–µ–∑ –≥–æ–¥
```
name = (input('–ò–º—è: '))
age = int(input('–í–æ–∑—Ä–∞—Å—Ç: '))
print('–ü—Ä–∏–≤–µ—Ç, ', name, '! –ß–µ—Ä–µ–∑ –≥–æ–¥ —Ç–µ–±–µ –±—É–¥–µ—Ç ', age+1, '.', sep='')
```

![‚Ññ1 - –í—ã–≤–æ–¥ –ø–µ—Ä–≤–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è](img/lab01/img-01.png)
### ‚Ññ2 - –í—ã–≤–æ–¥ –ø—Ä–≥—Ä–∞–º–º—ã: —Å—É–º–º–∞ –∏ —Å—Ä–µ–¥–Ω–µ–µ —á–∏—Å–ª–æ
```
a = float(input('a: ').replace(',', '.'))
b = float(input('b: ').replace(',', '.'))
sum = round(a+b, 2)
avg = round(sum/2, 2)
print('sum=',sum,'; avg=', avg, sep = '')
```

![‚Ññ2 - –í—ã–≤–æ–¥ –≤—Ç–æ—Ä–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è](img/lab01/img-02.png)
### ‚Ññ3 - –í—ã–≤–æ–¥ –ø—Ä–≥—Ä–∞–º–º—ã: –±–∞–∑–∞ –ø–æ—Å–ª–µ —Å–∫–∏–¥–∫–∏, –ù–î–°, –∏—Ç–æ–≥ –∫ –æ–ø–ª–∞—Ç–µ
```
price = float(input('–¶–µ–Ω–∞(‚ÇΩ): ').replace(',','.'))
discount = float(input('–°–∫–∏–¥–∫–∞(%): ').replace(',','.'))
vat = float(input('–ù–î–°(%): ').replace(',','.'))
base = price * (1 - discount/100)
vat_amount = base * (vat/100)
total = base + vat_amount
print(f'–ë–∞–∑–∞ –ø–æ—Å–ª–µ —Å–∫–∏–¥–∫–∏: {base:.2f} ‚ÇΩ')
print(f'–ù–î–°: {vat_amount:.2f} ‚ÇΩ')
print(f'–ò—Ç–æ–≥–æ –∫ –æ–ø–ª–∞—Ç–µ: {total:.2f} ‚ÇΩ')
```

![‚Ññ3 - –í—ã–≤–æ–¥ —Ç—Ä–µ—Ç—å–µ–≥–æ –∑–∞–¥–∞–Ω–∏—è](img/lab01/img-03.png)
### ‚Ññ4 - –í—ã–≤–æ–¥ –ø—Ä–≥—Ä–∞–º–º—ã: –≤—Ä–µ–º—è
```
m = int(input('–ú–∏–Ω—É—Ç—ã:'))
hours = m // 60
minutes = m % 60
print(f"{hours}:{minutes:02d}")
```

![‚Ññ4 - –í—ã–≤–æ–¥ —á–µ—Ç–≤–µ—Ä—Ç–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è](img/lab01/img-04.png)
### ‚Ññ5 -  –í—ã–≤–æ–¥ –ø—Ä–≥—Ä–∞–º–º—ã: –∏–Ω–∏—Ü–∏–∞–ª—ã –∏ —Ü–µ–Ω–∞
```
name = input('–§–ò–û:').strip()
parts = name.split()
initials = ''.join(part[0].upper() for part in parts) + '.'
length =len(' '.join(parts))
print('–ò–Ω–∏—Ü–∏–∞–ª—ã:', initials)
print('–î–ª–∏–Ω–∞ (—Å–∏–º–≤–æ–ª–æ–≤):', length)
```

![‚Ññ5 - –í—ã–≤–æ–¥ –ø—è—Ç–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è](img/lab01/img-05.png)

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ2
### ‚Ññ1 –†–∞–±–æ—Ç–∞ —Å–æ —Å–ø–∏—Å–∫–∞–º–∏
```
def min_max(nums: list[float | int]) -> tuple[float | int, float | int]:
    if not nums:
        raise ValueError("–°–ø–∏—Å–æ–∫ –ø—É—Å—Ç")
    min_n = nums[0]
    max_n = nums[0]
    for num in nums:
        if num < min_n:
            min_n = num
        if num > max_n:
            max_n = num
    return (min_n, max_n)

def unique_sorted(nums: list[float | int]) -> list[float | int]:
    return sorted(set(nums))



def flatten(mat: list[list | tuple]) -> list:
    result = []
    for item in mat:
        if not isinstance(item, (list, tuple)):
            raise TypeError("–°—Ç—Ä–æ–∫–∞ –Ω–µ —Å—Ç—Ä–æ–∫–∞ —Å—Ç—Ä–æ–∫ –º–∞—Ç—Ä–∏—Ü—ã")
        
        result.extend(item)
    
    return result


print(min_max([3, -1, 5, 5, 0]))
print(min_max([42]))
print(min_max([-5, -2, -9]))
#print(min_max([ ]))
print(min_max([1.5, 2, 2.0, -3.1]))

print(unique_sorted([3, 1, 2, 1, 3]))
print(unique_sorted([]))
print(unique_sorted([-1, -1, 0, 2, 2]))
print(unique_sorted([1.0, 1, 2.5, 2.5, 0]))

print(flatten([[1, 2], [3, 4]]))
print(flatten(([1, 2], (3, 4, 5))))
print(flatten([[1], [], [2, 3]]))
#print(flatten([[1, 2], 'ab']))

```
![(error 1)](img/lab02/img-2-01.png)
![error 2)](img/lab02/img-2-02.png)
![–í—ã–≤–æ–¥ –ø–µ—Ä–≤–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è](img/lab02/img-2-03.png)
### ‚Ññ2 –§—É–Ω–∫—Ü–∏–∏ (–¥–ª—è –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã—Ö –º–∞—Ç—Ä–∏—Ü)
```
def check_rec(mat: list[list]) -> tuple[int, int]:
    if not mat:
        return 0, 0
    
    rows = len(mat)
    cols = len(mat[0])
    
    for i in range(rows):
        if len(mat[i]) != cols:
            raise ValueError("–ú–∞—Ç—Ä–∏—Ü–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–æ–π")
    
    return rows, cols

def transpose(mat: list[list[float | int]]) -> list[list]:
    rows, cols = check_rec(mat)
    if rows == 0:
        return []
    
    result = []
    for j in range(cols):
        new_row = []
        for i in range(rows):
            new_row.append(mat[i][j])
        result.append(new_row)
    
    return result

def row_sums(mat: list[list[float | int]]) -> list[float]:
    rows, cols = check_rec(mat)
    
    if rows == 0:
        return []
    
    sums = []
    for i in range(rows):
        row_sum = 0
        for j in range(cols):
            row_sum += mat[i][j]
        sums.append(row_sum)
    
    return sums

def col_sums(mat: list[list[float | int]]) -> list[float]:

    rows, cols = check_rec(mat)
    
    if cols == 0:
        return []
    
    sums = []
    for j in range(cols):
        col_sum = 0
        for i in range(rows):
            col_sum += mat[i][j]
        sums.append(col_sum)
    
    return sums

print(transpose([[1, 2, 3]]))
print(transpose([[1], [2], [3]]))
print(transpose([[1, 2], [3, 4]]))
print(transpose([ ]))
#print(transpose([[1, 2], [3]]))

print(row_sums([[1, 2, 3], [4, 5, 6]]))
print(row_sums([[-1, 1], [10, -10]]))
print(row_sums([[0, 0], [0, 0]]))
#print(row_sums([[1, 2], [3]]))

print(col_sums([[1, 2, 3], [4, 5, 6]]))
print(col_sums([[-1, 1], [10, -10]]))
print(col_sums([[0, 0], [0, 0]]))
#print(col_sums([[1, 2], [3]]))

```
![(error 1)](img/lab02/img-2-04.png)
![–í—ã–≤–æ–¥ –≤—Ç–æ—Ä–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è](img/lab02/img-2-05.png)

### ‚Ññ3 –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π
```
def format_record(rec: tuple[str, str, float]) -> str:
    
    if not isinstance(rec, tuple):
        raise TypeError("–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫–æ—Ä—Ç–µ–∂–µ–º")
    
    if len(rec) != 3:
        raise ValueError("–ö–æ—Ä—Ç–µ–∂ –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 3 —ç–ª–µ–º–µ–Ω—Ç–∞: (–§–ò–û, –≥—Ä—É–ø–ø–∞, GPA)")
    
    fio, group, gpa = rec
    
    if not isinstance(fio, str):
        raise TypeError("–§–ò–û –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π")
    
    if not isinstance(group, str):
        raise TypeError("–ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π")
    
    if not isinstance(gpa, (int, float)):
        raise TypeError("GPA –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —á–∏—Å–ª–æ–º")
    
    if not fio.strip():
        raise ValueError("–§–ò–û –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
    
    if not group.strip():
        raise ValueError("–ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
    
    if gpa < 0 or gpa > 5.0:  
        raise ValueError("GPA –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –æ—Ç 0 –¥–æ 5.0")
    

    fio_parts = [part.strip() for part in fio.split() if part.strip()]
    

    if len(fio_parts) < 2:
        raise ValueError("–§–ò–û –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ñ–∞–º–∏–ª–∏—é –∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –∏–º—è")
    

    capital_parts = []
    for part in fio_parts:
        if not part:  
            raise ValueError("–ß–∞—Å—Ç–∏ –§–ò–û –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º–∏")
        capital_parts.append(part[0].upper() + part[1:].lower())
    

    initials = []
    for name in capital_parts[1:]:  
        if len(name) < 1:
            raise ValueError("–ò–º–µ–Ω–∞ –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º–∏")
        initials.append(f"{name[0].upper()}.")
    

    formatted_fio = f"{capital_parts[0]} {' '.join(initials)}"
    

    formatted_gpa = f"{gpa:.2f}"
    

    return f"{formatted_fio}, –≥—Ä. {group}, GPA {formatted_gpa}"



print(format_record(("–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á", "BIVT-25", 4.6)))
print(format_record(("  —Å–∏–¥–æ—Ä–æ–≤–∞  –∞–Ω–Ω–∞   —Å–µ—Ä–≥–µ–µ–≤–Ω–∞ ", "ABB-01", 3.999)))
print(format_record(["–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä", "IKBO-12", 5.0]))
print(format_record(["–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä –ü–µ—Ç—Ä–æ–≤–∏—á", "IKBO-12", 5.0]))

```
![(error 1)](img/lab02/img-2-006.png)
![–í—ã–≤–æ–¥ —Ç—Ä–µ—Ç—å–µ–≥–æ –∑–∞–¥–∞–Ω–∏—è](img/lab02/img-2-007.png)

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ3
### ‚Ññ1 - text.py
###### –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞, —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —Å–ª–æ–≤–∞, –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–Ω–∏–µ —á–∞—Å—Ç–æ—Ç—ã –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É –∏ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã


```
import re


def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç: –ø—Ä–∏–≤–æ–¥–∏—Ç —Ä–µ–≥–∏—Å—Ç—Ä, –∑–∞–º–µ–Ω—è–µ—Ç —ë –Ω–∞ –µ, —É–±–∏—Ä–∞–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã."""
    if not isinstance(text, str):
        raise TypeError("–¢–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π")
    
    if not text:
        return ""
    
    
    if yo2e:
        text = text.replace('—ë', '–µ').replace('–Å', '–ï')
    
    
    if casefold:
        text = text.casefold()
    
    
    text = re.sub(r'[\t\r\n]+', ' ', text)
    
    
    text = re.sub(r'\s+', ' ', text)
    
    return text.strip()


def tokenize(text: str) -> list[str]:
    """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Ç–æ–∫–µ–Ω—ã (—Å–ª–æ–≤–∞)."""
    if not isinstance(text, str):
        raise TypeError("–¢–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π")
    
    if not text:
        return []
    
    
    pattern = r'\b\w+(?:-\w+)*\b'
    tokens = re.findall(pattern, text)
    
    return tokens


def count_freq(tokens: list[str]) -> dict[str, int]:
    """–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —á–∞—Å—Ç–æ—Ç—É –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–æ–≤."""
    if not isinstance(tokens, list):
        raise TypeError("–¢–æ–∫–µ–Ω—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º")
    
    freq_dict = {}
    for token in tokens:
        freq_dict[token] = freq_dict.get(token, 0) + 1
    
    return freq_dict


def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ø-N —Å–∞–º—ã—Ö —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤."""
    if not isinstance(freq, dict):
        raise TypeError("–ß–∞—Å—Ç–æ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º")
    if not isinstance(n, int) or n < 0:
        raise ValueError("n –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–µ–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º —Ü–µ–ª—ã–º —á–∏—Å–ª–æ–º")
    
    if not freq:
        return []
    
    
    items = list(freq.items())
    
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã, –ø—Ä–∏ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ - –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É
    items.sort(key=lambda x: (-x[1], x[0]))
    
    return items[:n]

if __name__ == "__main__":

    print(normalize('–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t'))
    print(normalize('—ë–∂–∏–∫, –Å–ª–∫–∞'))
    print(normalize('Hello\r\nWorld'))
    print(normalize('  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  '))

    print(tokenize('–ø—Ä–∏–≤–µ—Ç –º–∏—Ä'))
    print(tokenize('hello,world!!!'))
    print(tokenize('–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ'))
    print(tokenize('2025 –≥–æ–¥'))
    print(tokenize('emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ'))

    tokence1 = count_freq(["a", "b", "a", "c", "b", "a"])
    print(tokence1)
    print(top_n(tokence1, 2))

    tokence2 = count_freq(["bb","aa","bb","aa","cc"])
    print(tokence2)
    print(top_n(tokence2, 2))


```
![‚Ññ1 - –í—ã–≤–æ–¥ –≤—Ç–æ—Ä–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è](img/lab03/img-3-02.png)

### ‚Ññ2 - text_stats.py

###### –ù–∞—Ö–æ–¥–∏—Ç –∫–æ–ª-–≤–æ —Å–ª–æ–≤ –∏ –∫–æ–ª-–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤, –∞ —Ç–∞–∫–∂–µ —Ç–æ–ø-5 —Å–ª–æ–≤. –í–≤–æ–¥ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —á–µ—Ä–µ–∑ —Ç–µ—Ä–º–∏–Ω–∞–ª —Ç–∞–∫–∏–º —Å–ø–æ—Å–æ–±–æ–º: echo "–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä! –ü—Ä–∏–≤–µ—Ç!!!" | python3 src/lab03/text_stats.py

```

import sys

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ —Ç–æ–π –∂–µ –ø–∞–ø–∫–∏
try:
    from lib.text import normalize, tokenize, count_freq, top_n
except ImportError:
    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∏–º–ø–æ—Ä—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    import os
    import sys
    sys.path.append(os.path.dirname(os.path.dirname(__file__)))
    from lib.text import normalize, tokenize, count_freq, top_n


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∏–ø—Ç–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ç–µ–∫—Å—Ç–∞."""
    # –ß–∏—Ç–∞–µ–º –≤–µ—Å—å –≤–≤–æ–¥ –∏–∑ stdin
    text = sys.stdin.read()
    
    if not text.strip():
        print("–í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç –ø—É—Å—Ç")
        return
    
    try:
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç
        normalized_text = normalize(text)
        tokens = tokenize(normalized_text)
        freq_dict = count_freq(tokens)
        top_words = top_n(freq_dict, 5)
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(tokens)}")
        print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(freq_dict)}")
        print("–¢–æ–ø-5:")
        
        for word, count in top_words:
            print(f"{word}:{count}")
            
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()


```
![‚Ññ2 - –í—ã–≤–æ–¥ –≤—Ç–æ—Ä–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è](img/lab03/img-3-03.png)
![‚Ññ2 - –í—ã–≤–æ–¥ –≤—Ç–æ—Ä–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è](img/lab03/img-3-04.png)

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ4
### ‚Ññ1 - io_txt_csv.py
###### read_text - —á–∏—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–∞–∫ —Å—Ç—Ä–æ–∫—É. –ß—Ç–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ UTF-8 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é. –î–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ñ–∞–π–ª–∞–º–∏ –≤ —Ä–∞–∑–Ω—ã—Ö –∫–æ–¥–∏—Ä–æ–≤–∫–∞—Ö –º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å: "utf-8" (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é), "cp1251" –∏–ª–∏ "windows-1251" (—Ä—É—Å—Å–∫–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞ Windows), "koi8-r" (—Ä—É—Å—Å–∫–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞ –¥–ª—è UNIX-—Å–∏—Å—Ç–µ–º), "iso-8859-5" (–¥—Ä—É–≥–∞—è —Ä—É—Å—Å–∫–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞), "cp866" (—Ä—É—Å—Å–∫–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞ DOS). 
###### write_csv - –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ CSV.
###### ensure_parent_dir - —Å–æ–∑–¥–∞–µ—Ç —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç.

```
import csv
from pathlib import Path
from typing import Iterable, Sequence

def read_text(path: str | Path, encoding: str = "utf-8") -> str:
    """–ß–∏—Ç–∞–µ—Ç —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç."""
    """
        –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç –≤—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É, –Ω–∞–ø—Ä–∏–º–µ—Ä: encoding="cp1251"
        –¥–ª—è —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –≤ Windows –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
    """
    p = Path(path)

    if not p.exists():
        raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
    
    try:
        return p.read_text(encoding=encoding)
    except UnicodeDecodeError:
        raise


def write_csv(rows: Iterable[Sequence], path: str | Path,
              header: tuple[str, ...] | None = None) -> None:
    p = Path(path)
    rows = list(rows)
    """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ CSV —Ñ–∞–π–ª."""
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –¥–ª–∏–Ω—ã —Å—Ç—Ä–æ–∫
    if rows:
        first_len = len(rows[0])
        for i, row in enumerate(rows):
            if len(row) != first_len:
                raise ValueError(f"–°—Ç—Ä–æ–∫–∞ {i} –∏–º–µ–µ—Ç –¥–ª–∏–Ω—É {len(row)}, –æ–∂–∏–¥–∞–µ—Ç—Å—è {first_len}")

    ensure_parent_dir(path)

    with p.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        if header is not None:
            w.writerow(header)
        for r in rows:
            w.writerow(r)

def ensure_parent_dir(path: str | Path) -> None:
    """–°–æ–∑–¥–∞–µ—Ç —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç."""
    Path(path).parent.mkdir(parents=True, exist_ok=True)

if __name__ == "__main__":
    txt = read_text("data/input.txt")  # –¥–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å —Å—Ç—Ä–æ–∫—É
    print("–ü—Ä–æ—á–∏—Ç–∞–Ω–æ:", txt)
    write_csv([("word","count"),("test",3)], "data/check.csv") 
    print("CSV —Å–æ–∑–¥–∞–Ω")


```
###### –í—ã–≤–æ–¥ –ø–µ—Ä–≤–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è
![‚Ññ1 - –í—ã–≤–æ–¥ –ø–µ—Ä–≤–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è](img/lab04/img-4-01.png)


### ‚Ññ2 - text_report.py
###### –°–∫—Ä–∏–ø—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª, –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤ –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç CSV –æ—Ç—á–µ—Ç.

```
import sys
from collections import Counter

try:
    from lab04.io_txt_csv import read_text, write_csv, ensure_parent_dir
except ImportError:
    #–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∏–º–ø–æ—Ä—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    import os
    sys.path.append(os.path.dirname(os.path.dirname(__file__)))
    from lab04.io_txt_csv import read_text, write_csv, ensure_parent_dir
from lib.text import normalize, tokenize, count_freq, top_n

def frequencies_from_text(text: str) -> dict[str, int]:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–∞—Å—Ç–æ—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞ .
    """
    tokens = tokenize(normalize(text))
    return Counter(tokens)

def sorted_word_counts(freq: dict[str, int]) -> list[tuple[str, int]]:
    """
    –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —á–∞—Å—Ç–æ—Ç –ø–æ —à–∞–±–ª–æ–Ω—É: (-—á–∞—Å—Ç–æ—Ç–∞, —Å–ª–æ–≤–æ).
    """
    return sorted(freq.items(), key=lambda kv: (-kv[1], kv[0]))

def generate_report():
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –ø–æ —á–∞—Å—Ç–æ—Ç–∞–º —Å–ª–æ–≤.
    """
    input_file = "data/input.txt"
    output_file = "data/report.csv"
    
    try:
        # 1 –ß—Ç–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ 
        text = read_text(input_file)
        
        # 2 –ü–æ–¥—Å—á–µ—Ç —á–∞—Å—Ç–æ—Ç —á–µ—Ä–µ–∑ —à–∞–±–ª–æ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
        freq = frequencies_from_text(text)
        
        # 3 –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —à–∞–±–ª–æ–Ω—É
        sorted_words = sorted_word_counts(freq)
        
        # 4 –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        ensure_parent_dir(output_file)
        write_csv(sorted_words, output_file, header=("word", "count"))
        
        # 5 –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ –∫–æ–Ω—Å–æ–ª—å
        tokens = tokenize(normalize(text))
        print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(tokens)}")
        print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(freq)}")
        print("–¢–æ–ø-5:")
        
        for word, count in top_n(freq, 5):
            print(f"{word}: {count}")
            

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞: {e}")
        sys.exit(1)

if __name__ == "__main__":
    generate_report()


```
###### –í—ã–≤–æ–¥ –ø—Ä–∏ input.txt - –ü—Ä–∏–≤–µ—Ç, –º–∏—Ä! –ü—Ä–∏–≤–µ—Ç!!!
![‚Ññ2 - –í—ã–≤–æ–¥ –≤—Ç–æ—Ä–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è](img/lab04/img-4-02.png)
###### report.csv –ø—Ä–∏ input.txt - –ü—Ä–∏–≤–µ—Ç, –º–∏—Ä! –ü—Ä–∏–≤–µ—Ç!!!
![‚Ññ2 - –í—ã–≤–æ–¥ –≤—Ç–æ—Ä–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è](img/lab04/img-4-03.png)
###### report.csv –ø—Ä–∏ –ø—É—Å—Ç–æ–º input.txt 
![‚Ññ2 - –í—ã–≤–æ–¥ –≤—Ç–æ—Ä–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è](img/lab04/img-4-04.png)
###### –í—ã–≤–æ–¥ –ø—Ä–∏ input.txt –≤ cp1251 —Å —Ç–µ–∫—Å—Ç–æ–º –ü—Ä–∏–≤–µ—Ç
![‚Ññ2 - –í—ã–≤–æ–¥ –≤—Ç–æ—Ä–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è](img/lab04/img-4-05.png)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ5
### ‚Ññ1 - json_csv.py
###### –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑ json –≤ csv –∏ –∏–∑ csv –≤ json

```

import json
import csv
from pathlib import Path

def json_to_csv(json_path: str, csv_path: str) -> None:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç JSON-—Ñ–∞–π–ª –≤ CSV."""
    if Path(json_path).suffix != '.json' or Path(csv_path).suffix != '.csv':
        raise TypeError("–ù–µ–≤–µ—Ä–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞")
    
    with open(json_path, encoding="utf-8") as f: 
        data = json.load(f)
    
    if not data or not isinstance(data, list) or not all(isinstance(item, dict) for item in data):
        raise ValueError("–ü—É—Å—Ç–æ–π JSON –∏–ª–∏ –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞")
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª—é—á–∏ –∏–∑ –≤—Å–µ—Ö –æ–±—ä–µ–∫—Ç–æ–≤
    fieldnames = sorted({key for item in data for key in item.keys()})
    
    with open(csv_path, "w", newline="", encoding="utf-8") as cf:
        writer = csv.DictWriter(cf, fieldnames=fieldnames)
        writer.writeheader()
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è –ø—É—Å—Ç—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏
        for item in data:
            row = {field: item.get(field, '') for field in fieldnames}
            writer.writerow(row)

def csv_to_json(csv_path: str, json_path: str) -> None:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç CSV –≤ JSON (—Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π)."""
    if Path(csv_path).suffix != '.csv' or Path(json_path).suffix != '.json':
        raise TypeError("–ù–µ–≤–µ—Ä–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞")
    
    with open(csv_path, 'r', encoding='utf-8', newline='') as cf:
        reader = csv.DictReader(cf)
        lt_rows = list(reader)
        
    if not lt_rows:
        raise ValueError("CSV —Ñ–∞–π–ª –ø—É—Å—Ç –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫")
    
    with open(json_path, 'w', encoding='utf-8') as jf:
        json.dump(lt_rows, jf, ensure_ascii=False, indent=2)


csv_to_json('data/samples/people.csv', 'data/out/people_from_csv.json')
json_to_csv("data/samples/people.json", "data/out/people_from_json.csv")

```
###### –°–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ csv –∏ json
![‚Ññ1 - –ø–µ—Ä–≤–æ–µ –∑–∞–¥–∞–Ω–∏–µ](img/lab05/img-1.png)
![‚Ññ1 - –ø–µ—Ä–≤–æ–µ –∑–∞–¥–∞–Ω–∏–µ](img/lab05/img-2.png)

### ‚Ññ2 - csv_xlsx.py
###### –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑ csv –≤ xlsx

```
from openpyxl import Workbook
import csv
from pathlib import Path

def csv_to_xlsx(csv_path: str, xlsx_path: str) -> None:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç CSV –≤ XLSX."""
    if not Path(csv_path).exists():
        raise FileNotFoundError(f"CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {csv_path}")
    
    wb = Workbook()
    ws = wb.active
    ws.title = "Sheet1"
    
    try:
        with open(csv_path, encoding="utf-8") as f:
            reader = csv.reader(f)
            rows = list(reader)
            
            if not rows:
                raise ValueError("CSV —Ñ–∞–π–ª –ø—É—Å—Ç")
            
            for row in rows:
                ws.append(row)
            
            # –ê–≤—Ç–æ—à–∏—Ä–∏–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
            for column in ws.columns:
                if column:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–æ–ª–æ–Ω–∫–∞ –Ω–µ –ø—É—Å—Ç–∞—è
                    mx = max(len(str(cell.value)) for cell in column)
                    ws.column_dimensions[column[0].column_letter].width = max(mx + 2, 8)
        
        wb.save(xlsx_path)
        
    except csv.Error as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è CSV: {e}")
    
csv_to_xlsx('data/samples/cities.csv', 'data/out/cities.xlsx')
csv_to_xlsx('data/samples/people.csv', 'data/out/people.xlsx')

```
![‚Ññ2 - –≤—Ç–æ—Ä–æ–≥–æ –∑–∞–¥–∞–Ω–∏–µ](img/lab05/img-3.png)
![‚Ññ2 - –≤—Ç–æ—Ä–æ–≥–æ –∑–∞–¥–∞–Ω–∏–µ](img/lab05/img-4.png)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ6
### ‚Ññ1 - cli_text.py
###### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Å–æ–ª—å–Ω—ã—Ö —É—Ç–∏–ª–∏—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–∫—Å—Ç–æ–º

```
import argparse
from pathlib import Path

try:
    from lib.text import normalize, tokenize, count_freq, top_n
except ImportError:
    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∏–º–ø–æ—Ä—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    import os
    import sys
    sys.path.append(os.path.dirname(os.path.dirname(__file__)))
    from lib.text import normalize, tokenize, count_freq, top_n


def main():
    parser = argparse.ArgumentParser(description="CLI‚Äë—É—Ç–∏–ª–∏—Ç—ã")
    subparsers = parser.add_subparsers(dest="command")

    # –ø–æ–¥–∫–æ–º–∞–Ω–¥–∞ cat 
    cat_parser = subparsers.add_parser("cat", help="–í—ã–≤–µ—Å—Ç–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞")
    cat_parser.add_argument("--input", required=True, help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è –≤—ã–≤–æ–¥–∞")
    cat_parser.add_argument("-n", action="store_true", help="–ù—É–º–µ—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫–∏")

    # –ø–æ–¥–∫–æ–º–∞–Ω–¥–∞ stats 
    stats_parser = subparsers.add_parser("stats", help="–ß–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤")
    stats_parser.add_argument("--input", required=True, help="–ü—É—Ç—å –∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É —Ñ–∞–π–ª—É")
    stats_parser.add_argument("--top", type=int, default=5, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø-—Å–ª–æ–≤")

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return

    file_path = Path(args.input)
    if not file_path.exists():
        parser.error(f"–§–∞–π–ª '{args.input}' –Ω–µ –Ω–∞–π–¥–µ–Ω")

    if args.command == "cat":
        try:
            with file_path.open("r", encoding="utf-8") as f:
                for i, line in enumerate(f, start=1):
                    line = line.rstrip("\n")
                    if args.n:
                        print(f"{i:6}  {line}")
                    else:
                        print(line)
        except Exception as e:
            parser.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")

    elif args.command == "stats":
        try:
            with file_path.open("r", encoding="utf-8") as f:
                text = f.read()
            
            normalized = normalize(text)
            words = tokenize(normalized)
            freq = count_freq(words)
            top_words = top_n(freq, args.top)

            if not top_words:
                print("–°–ª–æ–≤–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ —Ñ–∞–π–ª–µ")
                return

            print(f"–¢–æ–ø-{args.top} —Å–∞–º—ã—Ö —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤:")
            print("–°–ª–æ–≤–æ\t\t–ß–∞—Å—Ç–æ—Ç–∞")
            print("-" * 20)
            for word, count in top_words:
                print(f"{word:<15} {count}")

        except Exception as e:
            parser.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ç–µ–∫—Å—Ç–∞: {e}")

if __name__ == "__main__":
    main()

```
![‚Ññ1 - –Ω—É–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–æ–∫](img/lab06/img-6-01.png)
![‚Ññ1 - —á–∞—Å—Ç–æ—Ç–∞ —Å–ª–æ–≤](img/lab06/img-6-02.png)
![‚Ññ1 - –ø–æ–∫–∞–∑](img/lab06/img-6-06.png)


### ‚Ññ2 - cli_convert.py
###### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Å–æ–ª—å–Ω—ã—Ö —É—Ç–∏–ª–∏—Ç –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É —Ñ–æ—Ä–º–∞—Ç–∞–º–∏

```
import argparse
from pathlib import Path
try:
    from lab05.json_csv import *
except ImportError:
    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∏–º–ø–æ—Ä—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    import os
    import sys
    sys.path.append(os.path.dirname(os.path.dirname(__file__)))
    from lab05.json_csv import *
try:
    from lab05.csv_xlsx import *
except ImportError:
    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∏–º–ø–æ—Ä—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    import os
    import sys
    sys.path.append(os.path.dirname(os.path.dirname(__file__)))
    from lab05.csv_xlsx import *

def main():
    parser = argparse.ArgumentParser(description="–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä JSON –≤ CSV, CSV –≤ JSON, CSV –≤ XLSX")
    sub = parser.add_subparsers(dest="cmd")

    # json ‚Üí csv
    json2csv_parser = sub.add_parser("json2csv", help="–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å JSON –≤ CSV")
    json2csv_parser.add_argument("--in", dest="input", required=True, help="–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É JSON")
    json2csv_parser.add_argument("--out", dest="output", required=True, help="–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É CSV")

    # csv ‚Üí json
    csv2json_parser = sub.add_parser("csv2json", help="–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å CSV –≤ JSON")
    csv2json_parser.add_argument("--in", dest="input", required=True, help="–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É CSV")
    csv2json_parser.add_argument("--out", dest="output", required=True, help="–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É JSON")

    # csv ‚Üí xlsx
    csv2xlsx_parser = sub.add_parser("csv2xlsx", help="–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å CSV –≤ XLSX")
    csv2xlsx_parser.add_argument("--in", dest="input", required=True, help="–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É CSV")
    csv2xlsx_parser.add_argument("--out", dest="output", required=True, help="–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É XLSX")

    args = parser.parse_args()

    if not args.cmd:
        parser.print_help()
        return

    input_path = Path(args.input)
    if not input_path.exists():
        parser.error(f"–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª '{args.input}' –Ω–µ –Ω–∞–π–¥–µ–Ω")

    # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    try:
        if args.cmd == "json2csv":
            json_to_csv(args.input, args.output)
            print(f"–£—Å–ø–µ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {args.input} -> {args.output}")
            
        elif args.cmd == "csv2json":
            csv_to_json(args.input, args.output)
            print(f"–£—Å–ø–µ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {args.input} -> {args.output}")
            
        elif args.cmd == "csv2xlsx":
            csv_to_xlsx(args.input, args.output)
            print(f"–£—Å–ø–µ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {args.input} -> {args.output}")
            
    except Exception as e:
        parser.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}")


if __name__ == "__main__":
    main()

```

![‚Ññ2 - json](img/lab06/img-6-03.png)
![‚Ññ2 - csv](img/lab06/img-6-04.png)
![‚Ññ2 - xlsx](img/lab06/img-6-05.png)
![‚Ññ2 - –ø–æ–∫–∞–∑](img/lab06/img-6-07.png)



# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ7
### ‚Ññ1 - —Ç–µ—Å—Ç—ã –¥–ª—è src/lib/text.py (text_test.py)

```

import pytest

try:
    from src.lib.text import normalize, tokenize, count_freq, top_n
except ImportError:
    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∏–º–ø–æ—Ä—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    import os
    import sys

    sys.path.append(os.path.dirname(os.path.dirname(__file__)))
    from src.lib.text import normalize, tokenize, count_freq, top_n


@pytest.mark.parametrize(
    "source, expected",
    [
        ("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
        ("—ë–∂–∏–∫, –Å–ª–∫–∞", "–µ–∂–∏–∫, –µ–ª–∫–∞"),
        ("Hello\r\nWorld", "hello world"),
        ("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ", "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"),
        ("", ""),
        ("   ", ""),
        (3, TypeError)
    ],
)
def test_normalize(source, expected):
    if type(source) != str:
        with pytest.raises(expected):
            normalize(source) 
    else:
        assert normalize(source) == expected

    


@pytest.mark.parametrize(
    "text, expected",
    [
        ("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä", ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]),
        ("hello world test", ["hello", "world", "test"]),
        ("", []),
        ("   ", []),
        ("–∑–Ω–∞–∫–∏, –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è! —Ç–µ—Å—Ç.", ["–∑–Ω–∞–∫–∏", "–ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è", "—Ç–µ—Å—Ç"]),
    ],
)
def test_tokenize(text, expected):
    assert tokenize(text) == expected


def test_count_freq_basic():
    tokens = ["apple", "banana", "apple", "cherry", "banana", "apple"]
    result = count_freq(tokens)
    expected = {"apple": 3, "banana": 2, "cherry": 1}
    assert result == expected


def test_count_freq_empty():
    assert count_freq([]) == {}


def test_top_n_basic():
    freq = {"apple": 5, "banana": 3, "cherry": 7, "date": 1}
    result = top_n(freq, 2)
    expected = [("cherry", 7), ("apple", 5)]
    assert result == expected


def test_top_n_tie_breaker():
    freq = {"banana": 3, "apple": 3, "cherry": 3}
    result = top_n(freq, 3)
    expected = [("apple", 3), ("banana", 3), ("cherry", 3)]
    assert result == expected


def test_top_n_empty():
    assert top_n({}, 5) == []


def test_full_pipeline():
    text = "–ü—Ä–∏–≤–µ—Ç –º–∏—Ä! –ü—Ä–∏–≤–µ—Ç –≤—Å–µ–º. –ú–∏—Ä –ø—Ä–µ–∫—Ä–∞—Å–µ–Ω."
    normalized = normalize(text)
    tokens = tokenize(normalized)
    freq = count_freq(tokens)
    top_words = top_n(freq, 2)

    assert normalized == "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä! –ø—Ä–∏–≤–µ—Ç –≤—Å–µ–º. –º–∏—Ä –ø—Ä–µ–∫—Ä–∞—Å–µ–Ω."
    assert tokens == [
        "–ø—Ä–∏–≤–µ—Ç",
        "–º–∏—Ä",
        "–ø—Ä–∏–≤–µ—Ç",
        "–≤—Å–µ–º",
        "–º–∏—Ä",
        "–ø—Ä–µ–∫—Ä–∞—Å–µ–Ω",
    ]
    assert freq == {"–ø—Ä–∏–≤–µ—Ç": 2, "–º–∏—Ä": 2, "–≤—Å–µ–º": 1, "–ø—Ä–µ–∫—Ä–∞—Å–µ–Ω": 1}
    assert top_words == [("–º–∏—Ä", 2), ("–ø—Ä–∏–≤–µ—Ç", 2)]


```


### ‚Ññ2 - —Ç–µ—Å—Ç—ã –¥–ª—è src/lab05/json_csv.py (test_json_csv.py)

```

import pytest
import json
import csv

try:
    from lab05.json_csv import json_to_csv, csv_to_json
except ImportError:
    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∏–º–ø–æ—Ä—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    import os
    import sys

    sys.path.append(os.path.dirname(os.path.dirname(__file__)))
    from src.lab05.json_csv import json_to_csv, csv_to_json


# –ë–∞–∑–æ–≤—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è —É—Å–ø–µ—à–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
@pytest.mark.parametrize(
    "test_name,data,expected_count",
    [
        ("basic", [{"name": "Alice", "age": 25}, {"name": "Bob", "age": 30}], 2),
        (
            "complex_data",
            [{"name": "Alice", "age": 25, "active": True, "score": 95.5}],
            1,
        ),
        (
            "different_order",
            [{"name": "Alice", "age": 25}, {"age": 30, "name": "Bob"}],
            2,
        ),
        ("empty_values", [{"name": "Alice", "age": 25, "comment": ""}], 1),
        ("unicode", [{"name": "–ê–ª–∏—Å–∞", "message": "–ü—Ä–∏–≤–µ—Ç! üåç"}], 1),
    ],
)
def test_json_to_csv_success(tmp_path, test_name, data, expected_count):
    """–ü–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ç–µ—Å—Ç —É—Å–ø–µ—à–Ω—ã—Ö –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π JSON –≤ CSV"""
    src = tmp_path / f"{test_name}.json"
    dst = tmp_path / f"{test_name}.csv"

    src.write_text(json.dumps(data, ensure_ascii=False), encoding="utf-8")
    json_to_csv(str(src), str(dst))

    assert dst.exists()  # –ø—Ä–æ–≤–µ—Ä–∫–∞_—Å–æ–∑–¥–∞–Ω–∏—è_—Ñ–∞–π–ª–∞
    with dst.open(encoding="utf-8") as f:
        rows = list(csv.DictReader(f))

    assert len(rows) == expected_count
    assert rows[0]["name"] == data[0]["name"]


@pytest.mark.parametrize(
    "test_name,csv_content,expected_count",
    [
        ("basic", "name,age\nAlice,25\nBob,30", 2),
        (
            "special_chars",
            'name,description\n"Alice","Test, comma"',
            1,
        ),  # —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ_—Å–∏–º–≤–æ–ª—ã #–∫–∞–≤—ã—á–∫–∏
        ("semicolon_delim", "name;age\nAlice;25\nBob;30", 2),
    ],
)
def test_csv_to_json_success(tmp_path, test_name, csv_content, expected_count):
    """–ü–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ç–µ—Å—Ç —É—Å–ø–µ—à–Ω—ã—Ö –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π CSV –≤ JSON"""
    src = tmp_path / f"{test_name}.csv"  # –≤—Ö–æ–¥–Ω—ã–µ_–¥–∞–Ω–Ω—ã–µ
    dst = tmp_path / f"{test_name}.json"  # –≤—ã—Ö–æ–¥–Ω—ã–µ_–¥–∞–Ω–Ω—ã–µ

    src.write_text(csv_content, encoding="utf-8")
    csv_to_json(str(src), str(dst))

    assert dst.exists()
    with dst.open(encoding="utf-8") as f:
        data = json.load(f)  # –∑–∞–≥—Ä—É–∑–∫–∞_json

    assert len(data) == expected_count


# –¢–µ—Å—Ç—ã –¥–ª—è –æ—à–∏–±–æ–∫ JSON
@pytest.mark.parametrize(
    "test_name,file_content,expected_error",
    [
        ("file_not_found", None, FileNotFoundError),
        ("invalid_json", "{ invalid json }", ValueError),
        ("empty_file", "", ValueError),
        ("not_list", '{"name": "test"}', ValueError),
        ("empty_list", "[]", ValueError),
        ("mixed_list", '[{"name": "test"}, "not_dict"]', ValueError),
        ("invalid_encoding", b"\xff\xfe\x00\x00", ValueError),
    ],
)
def test_json_to_csv_errors(tmp_path, test_name, file_content, expected_error):
    """–ü–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ç–µ—Å—Ç –æ—à–∏–±–æ–∫ JSON –≤ CSV"""
    src = tmp_path / f"{test_name}.json"
    dst = tmp_path / "output.csv"

    if file_content is None:
        # –¢–µ—Å—Ç –¥–ª—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞
        with pytest.raises(expected_error):
            json_to_csv("nonexistent.json", str(dst))
    else:
        # –¢–µ—Å—Ç –¥–ª—è —Ñ–∞–π–ª–∞ —Å –æ—à–∏–±–∫–æ–π –≤ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º
        if isinstance(file_content, bytes):
            src.write_bytes(file_content)
        else:
            src.write_text(file_content, encoding="utf-8")

        with pytest.raises(expected_error):  # –ø—Ä–æ–≤–µ—Ä–∫–∞_–∏—Å–∫–ª—é—á–µ–Ω–∏—è
            json_to_csv(str(src), str(dst))


# –¢–µ—Å—Ç—ã –¥–ª—è –æ—à–∏–±–æ–∫ CSV
@pytest.mark.parametrize(
    "test_name,file_content,expected_error",
    [
        ("file_not_found", None, FileNotFoundError),
        ("empty_file", "", ValueError),
        ("empty_header", "\nAlice,25", ValueError),
        ("empty_columns", "name,,age\nAlice,25,30", ValueError),
        ("invalid_encoding", b"\xff\xfe\x00\x00", ValueError),
    ],
)
def test_csv_to_json_errors(tmp_path, test_name, file_content, expected_error):
    """–ü–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ç–µ—Å—Ç –æ—à–∏–±–æ–∫ CSV –≤ JSON"""
    src = tmp_path / f"{test_name}.csv"
    dst = tmp_path / "output.json"

    if file_content is None:
        # –¢–µ—Å—Ç –¥–ª—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞
        with pytest.raises(expected_error):
            csv_to_json("nonexistent.csv", str(dst))
    else:
        # –¢–µ—Å—Ç –¥–ª—è —Ñ–∞–π–ª–∞ —Å –æ—à–∏–±–∫–æ–π –≤ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º
        if isinstance(file_content, bytes):
            src.write_bytes(file_content)
        else:
            src.write_text(file_content, encoding="utf-8")

        with pytest.raises(expected_error):
            csv_to_json(str(src), str(dst))


# –°–ø–µ—Ü. —Ç–µ—Å—Ç—ã
def test_json_csv_roundtrip(tmp_path):
    """–¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è"""
    original_json = tmp_path / "original.json"
    intermediate_csv = tmp_path / "intermediate.csv"
    final_json = tmp_path / "final.json"

    original_data = [{"name": "Alice", "age": 25}, {"name": "Bob", "age": 30}]
    original_json.write_text(json.dumps(original_data), encoding="utf-8")

    json_to_csv(str(original_json), str(intermediate_csv))
    csv_to_json(str(intermediate_csv), str(final_json))

    with final_json.open(encoding="utf-8") as f:
        final_data = json.load(f)  # —á—Ç–µ–Ω–∏–µ_—Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

    assert len(final_data) == 2  # #–ø—Ä–æ–≤–µ—Ä–∫–∞_—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è_–¥–∞–Ω–Ω—ã—Ö
    assert final_data[0]["name"] == "Alice"  # –ø—Ä–æ–≤–µ—Ä–∫–∞_—Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏


def test_unexpected_errors(monkeypatch, tmp_path):
    """–¢–µ—Å—Ç –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã—Ö –æ—à–∏–±–æ–∫"""
    # –¢–µ—Å—Ç –¥–ª—è JSON
    src_json = tmp_path / "test.json"
    dst_json = tmp_path / "test.csv"
    src_json.write_text('[{"name": "test"}]', encoding="utf-8")

    def mock_getsize(path):
        raise RuntimeError("Unexpected error")

    monkeypatch.setattr("os.path.getsize", mock_getsize)  # –ø–æ–¥–º–µ–Ω–∞_—Ñ—É–Ω–∫—Ü–∏–∏

    with pytest.raises(ValueError, match="–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞"):
        json_to_csv(str(src_json), str(dst_json))

    # –¢–µ—Å—Ç –¥–ª—è CSV
    src_csv = tmp_path / "test.csv"
    dst_csv = tmp_path / "test.json"
    src_csv.write_text("name,age\nAlice,25", encoding="utf-8")
    original_open = open

    def mock_open(*args, **kwargs):
        if args[0].endswith(".csv") and "r" in args[1]:
            raise RuntimeError("Unexpected read error")
        return original_open(*args, **kwargs)

    monkeypatch.setattr("builtins.open", mock_open)

    with pytest.raises(ValueError, match="–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞"):
        csv_to_json(str(src_csv), str(dst_csv))


def test_csv_empty_data_with_header(tmp_path):
    """–¢–µ—Å—Ç –¥–ª—è CSV —Ç–æ–ª—å–∫–æ —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º"""
    src = tmp_path / "only_header.csv"
    dst = tmp_path / "test.json"

    src.write_text("name,age", encoding="utf-8")  # –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ_–ø—É—Å—Ç–æ–≥–æ_csv

    csv_to_json(str(src), str(dst))

    assert dst.exists()
    with dst.open(encoding="utf-8") as f:
        data = json.load(f)

    assert len(data) == 0  # –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫, —Ç–∞–∫ –∫–∞–∫ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö


def test_json_to_csv_wrong_extension(tmp_path):
    # –¢–µ—Å—Ç: JSON —Ñ–∞–π–ª —Å –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º
    src = tmp_path / "test.txt"  # –ù–µ .json —Ñ–∞–π–ª
    dst = tmp_path / "test.csv"

    src.write_text('[{"name": "test"}]', encoding="utf-8")  # json_–≤_txt_—Ñ–∞–π–ª–µ

    with pytest.raises(ValueError, match="–Ω–µ —è–≤–ª—è–µ—Ç—Å—è JSON —Ñ–∞–π–ª–æ–º"):
        json_to_csv(str(src), str(dst))


def test_csv_to_json_wrong_extension(tmp_path):
    # –¢–µ—Å—Ç: CSV —Ñ–∞–π–ª —Å –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º
    src = tmp_path / "test.txt"  # –ù–µ .csv —Ñ–∞–π–ª
    dst = tmp_path / "test.json"

    src.write_text("name,age\nAlice,25", encoding="utf-8")

    with pytest.raises(ValueError, match="–Ω–µ —è–≤–ª—è–µ—Ç—Å—è CSV —Ñ–∞–π–ª–æ–º"):
        csv_to_json(str(src), str(dst))


```
![black .](img/lab07/img-07-1.png)
![black --check . all done](img/lab07/img-07-2.png)
![black --check . oh no](img/lab07/img-07-3.png)
![black --check . oh no](img/lab07/img-07-4.png)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ8
### ‚Ññ1 - models.py (—Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Å–∞ Student)

```
from dataclasses import dataclass
from datetime import datetime, date
from typing import Dict, Any

@dataclass
class Student:
    fio: str
    birthdate: str
    group: str
    gpa: float

    def __post_init__(self):
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞—Ç—ã
        try:
            datetime.strptime(self.birthdate, "%Y-%m-%d")
        except ValueError:
            raise ValueError(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã: {self.birthdate}. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ YYYY-MM-DD")
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è GPA
        if not (0 <= self.gpa <= 5):
            raise ValueError(f"GPA –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç 0 –¥–æ 5, –ø–æ–ª—É—á–µ–Ω–æ: {self.gpa}")
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –§–ò–û 
        if len(self.fio.strip().split()) < 2:
            raise ValueError(f"–§–ò–û –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –º–∏–Ω–∏–º—É–º 2 —Å–ª–æ–≤–∞: {self.fio}")

    def age(self) -> int:
        birth_date = datetime.strptime(self.birthdate, "%Y-%m-%d").date()
        today = date.today()
        age = today.year - birth_date.year
        
        if (today.month, today.day) < (birth_date.month, birth_date.day):
            age -= 1
            
        return age

    def to_dict(self) -> Dict[str, Any]:
        return {
            "fio": self.fio,
            "birthdate": self.birthdate,
            "group": self.group,
            "gpa": self.gpa
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'Student':
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
        required = ['fio', 'birthdate', 'group', 'gpa']
        for field in required:
            if field not in data:
                raise KeyError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ: {field}")
        
        return cls(
            fio=str(data["fio"]),
            birthdate=str(data["birthdate"]),
            group=str(data["group"]),
            gpa=float(data["gpa"])
        )

    def __str__(self) -> str:
        return f"{self.fio}, {self.group}, GPA: {self.gpa:.2f}, –í–æ–∑—Ä–∞—Å—Ç: {self.age()}"
    

if __name__ == "__main__":
    try:
        student = Student(
            fio="–°–∏–¥–æ—Ä–æ–≤–∞ –ê–Ω–Ω–∞ –ü–µ—Ç—Ä–æ–≤–Ω–∞", # –ê—Ä–≥—É–º–µ–Ω—Ç: –§–ò–û
            birthdate="2005-06-28",
            group="SE-01",
            gpa=4.6
        )
        print(student)
        print(f"–°–ª–æ–≤–∞—Ä—å: {student.to_dict()}")
    except ValueError as e:
        print(f"–û—à–∏–±–∫–∞: {e}")

```

![models.py](img/lab08/img-08-01.png)


### ‚Ññ2 - serialize.py

```
import json
from typing import List
from models import Student

def students_to_json(students: List[Student], path: str) -> None:
    """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –±–∞–∑–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π"""
    if not students:
        print("–í–Ω–∏–º–∞–Ω–∏–µ: –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
        return
    
    data = [student.to_dict() for student in students]
    
    try:
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(students)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ {path}")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {e}")

def students_from_json(path: str) -> List[Student]:
    """–î–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    try:
        with open(path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
        return []
    except json.JSONDecodeError:
        print(f"–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ JSON –≤ —Ñ–∞–π–ª–µ: {path}")
        return []
    
    if not isinstance(data, list):
        print(f"–û–∂–∏–¥–∞–ª—Å—è —Å–ø–∏—Å–æ–∫, –ø–æ–ª—É—á–µ–Ω {type(data).__name__}")
        return []
    
    students = []
    errors = []
    
    for i, item in enumerate(data):
        try:
            student = Student.from_dict(item)
            students.append(student)
        except (ValueError, KeyError, TypeError) as e:
            errors.append(f"–°—Ç—Ä–æ–∫–∞ {i}: {e}")
    
    if errors:
        print("–ù–∞–π–¥–µ–Ω—ã –æ—à–∏–±–∫–∏ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ:")
        for error in errors:
            print(f"  - {error}")
    
    return students

if __name__ == "__main__": # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–ø—É—â–µ–Ω –ª–∏ —Å–∫—Ä–∏–ø—Ç –Ω–∞–ø—Ä—è–º—É—é
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    students = [
        Student("–ö–æ–º–∞—Ä–æ–≤ –°–µ—Ä–≥–µ–π", "2006-11-25", "SE-01", 4.6),
        Student("–ö–∞–ø–ª–∞–Ω –ê–ª–µ–∫—Å–µ–π", "2007-10-14", "SE-02", 4.4),
        Student("–ü–æ–ø–æ–≤–∞ –ê–ª–µ–∫—Å–∞–Ω–¥—Ä–∞", "2002-05-16", "SE-03", 3.8)
    ]
    
    # –°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è
    students_to_json(students, "data/lab08/students_output.json")
    
    # –î–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è
    loaded_students = students_from_json("data/lab08/students_input.json")
    for student in loaded_students:
        print(student)

```

![students_input.json](img/lab08/img-08-02.png)
![students_output.json](img/lab08/img-08-05.png)
![students_output.json](img/lab08/img-08-04.png)


