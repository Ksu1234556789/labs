import re
from collections import Counter


def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    if not isinstance(text, str):
        raise TypeError("–¢–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π")

    if casefold:
        text = text.casefold()
    if yo2e:
        translation_table = str.maketrans(
            {
                "—ë": "–µ",
                "–Å": "–ï",
            }
        )
        text = text.translate(translation_table)
    translation_table_controls = str.maketrans(
        {
            "\t": " ",
            "\r": " ",
            "\n": " ",
            "\v": " ",
            "\f": " ",
        }
    )
    text = text.translate(translation_table_controls)
    text = " ".join(text.split())

    return text


def tokenize(
    text: str,
) -> list[str]:
    word = re.findall(
        r"[\w-]+",
        text,
    )
    words = []
    for w in word:
        w = w.strip("_-")
        w = re.sub(
            r"-{2,}",
            "-",
            w,
        )
        w = re.sub(
            r"_{2,}",
            "_",
            w,
        )
        w = re.sub(
            r"[-_]{2,}",
            "-",
            w,
        )
        if w:
            words.append(w)
    return words


def count_freq(
    tokens: list[str],
) -> dict[str, int]:
    freq = Counter(tokens)
    return dict(freq)


def top_n(
    freqs: dict[
        str,
        int,
    ],
    n: int,
) -> list[
    tuple[
        str,
        int,
    ]
]:
    return sorted(
        freqs.items(),
        key=lambda x: (
            -x[1],
            x[0],
        ),
    )[:n]


# if __name__ == "__main__":

#   print(normalize("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t"))
#  print(normalize("—ë–∂–∏–∫, –Å–ª–∫–∞"))
# print(normalize("Hello\r\nWorld"))
# print(normalize("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  "))

# print(tokenize("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"))
# print(tokenize("hello,world!!!"))
# print(tokenize("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ"))
# print(tokenize("2025 –≥–æ–¥"))
# print(tokenize("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"))

# tokence1 = count_freq(["a", "b", "a", "c", "b", "a"])
# print(tokence1)
# print(top_n(tokence1, 2))

# tokence2 = count_freq(["bb", "aa", "bb", "aa", "cc"])
# print(tokence2)
# print(top_n(tokence2, 2))
